# MachineTranslation-Attention
The introduction of attention mechanism and its subsequent enhancement in the "Attention is All You Need" paper has transformed the NLP landscape. In this notebook, we will implement a custom encoder-decoder with attention mechanism architecture to solve the problem of machine translation.

# Objective
Translate Italian sequences to English sequences by implementing a attention based Seq2Seq model from scratch.

# Prerequisites
You need to have installed following softwares and libraries before running this project.

1. Python 3: https://www.python.org/downloads/
2. Anaconda: It will install ipython notebook and most of the libraries which are needed like sklearn, pandas, seaborn, matplotlib, numpy and scipy: https://www.anaconda.com/download/

# Getting Started
Start by downloading the project files and run the ".ipynb" file as a ipython-notebook (Jupyter notebook)

# Requirements
- Required libraries are:
  - numpy
  - pandas
  - tensorflow
  - keras
  - matplotlib
  - seaborn
  - python >= 3.7
  - Check the notebooks for more details

# Authors
- Mohammed Zoher
